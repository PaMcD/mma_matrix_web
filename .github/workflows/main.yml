name: Scrape Data

permissions:
  contents: write

on:
  schedule:
    # Runs every Monday at 4am UTC
    - cron: '0 4 * * 1'
  workflow_dispatch: # allows manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true    # use the built-in GITHUB_TOKEN for push

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install -r data_sourcing/requirements.txt

      - name: Run scraper
        run: |
          python data_sourcing/main.py

      - name: Configure git
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"

      - name: Stage and commit changes (if any)
        run: |
          git add assets/assets/
          git diff --staged --quiet || git commit -m "Update scraped data [skip ci]"

      - name: Push changes using GITHUB_TOKEN
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Push back to main (adjust target branch if needed)
          git push origin HEAD:main --follow-tags
